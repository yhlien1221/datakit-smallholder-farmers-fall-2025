{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and load \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('E://datakind_project//datakind_dataset.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cfb278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick info and basic stats (fast)\n",
    "print('rows,cols:', df.shape)\n",
    "\n",
    "display(df.select_dtypes(include=[np.number]).describe().transpose())\n",
    "display(df.select_dtypes(include=[object]).describe().transpose())\n",
    "# A small describe on object and numeric separatelyprint(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing / blank-like values summary \n",
    "n = len(df)\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / n * 100).round(6)\n",
    "obj_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "empty_counts = {}\n",
    "null_token_counts = {}\n",
    "tokens = {'nan', 'none', 'null', 'na', ''}\n",
    "for col in obj_cols:\n",
    "    s = df[col]\n",
    "    empty_counts[col] = int(s.apply(lambda x: isinstance(x, str) and x.strip() == '').sum())\n",
    "    null_token_counts[col] = int(s.dropna().astype(str).str.strip().str.lower().isin(tokens).sum())\n",
    "summary = pd.DataFrame({\n",
    "    'dtype': df.dtypes,\n",
    "    'missing_count': missing,\n",
    "    'missing_pct': missing_pct,\n",
    "    'empty_str_count': [empty_counts.get(c, 0) for c in df.columns],\n",
    "    'null_token_count': [null_token_counts.get(c, 0) for c in df.columns],\n",
    "})\n",
    "summary = summary.sort_values('missing_count', ascending=False)\n",
    "summary.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language distribution for question/answer/tips columns (if present)\n",
    "lang_cols = [c for c in df.columns if 'lang' in c.lower() or 'language' in c.lower()]\n",
    "print('Detected language columns:', lang_cols)\n",
    "for c in lang_cols:\n",
    "    print('Top values for', c)\n",
    "    display(df[c].value_counts(dropna=False).head(20))\n",
    "\n",
    "# If there's an explicit question language column like 'question_lang' or similar, count questions by language\n",
    "q_lang_candidates = [c for c in df.columns if 'question' in c and ('lang' in c or 'language' in c)]\n",
    "if q_lang_candidates:\n",
    "    qlc = q_lang_candidates[0]\n",
    "    print('Question counts by language (top):')\n",
    "    display(df[qlc].value_counts().head(20))\n",
    "\n",
    "# Fallback: try to detect language column 'language' or 'lang'\n",
    "if not q_lang_candidates and lang_cols:\n",
    "    display(df[lang_cols[0]].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographics overview (age, gender, country indicators if present)\n",
    "demo_cols = [c for c in df.columns if any(k in c.lower() for k in ['age','gender','sex','country','region','district'])]\n",
    "print('Detected demographic-like columns:', demo_cols)\n",
    "for c in demo_cols:\n",
    "    if df[c].dtype == 'object':\n",
    "        print('Top categories for', c)\n",
    "        display(df[c].value_counts(dropna=False).head(20))\n",
    "    else:\n",
    "        print('Summary for', c)\n",
    "        display(df[c].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify power users (by answers given and questions asked).\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# Canonical column names (as provided)\n",
    "asker_col = 'question_user_id'\n",
    "answerer_col = 'response_user_id'\n",
    "question_ts_col = 'question_sent'\n",
    "response_ts_col = 'response_sent'\n",
    "question_text_col = 'question_content'\n",
    "answer_text_col = 'response_content'\n",
    "language_col = 'question_language'\n",
    "country_col = 'question_user_country_code'\n",
    "topic_q_col = 'question_topic'\n",
    "topic_r_col = 'response_topic'\n",
    "\n",
    "# Verify required columns exist; if not, stop and ask for correction\n",
    "missing = [c for c in [asker_col, answerer_col, question_text_col, answer_text_col] if c not in df.columns]\n",
    "if missing:\n",
    "    print('The following required columns are missing from the dataframe:', missing)\n",
    "    print('Please provide the correct column names. I will not attempt fuzzy detection when you supplied names.')\n",
    "else:\n",
    "    top_n = 20\n",
    "    # Top askers\n",
    "    top_askers = df[asker_col].value_counts().head(top_n)\n",
    "    print(f'Top {top_n} askers (by question count):')\n",
    "    display(top_askers)\n",
    "\n",
    "    # Top answerers\n",
    "    top_answerers = df[answerer_col].value_counts().head(top_n)\n",
    "    print(f'Top {top_n} answerers (by response count):')\n",
    "    display(top_answerers)\n",
    "\n",
    "    # Save CSV of top users for manual review\n",
    "    rows = []\n",
    "    for user, cnt in top_askers.items():\n",
    "        rows.append({'user_id': str(user), 'role': 'asker', 'count': int(cnt)})\n",
    "    for user, cnt in top_answerers.items():\n",
    "        rows.append({'user_id': str(user), 'role': 'answerer', 'count': int(cnt)})\n",
    "    out_path = Path('challenge_1/top_power_users.csv')\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open('w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['user_id','role','count'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print('Saved top power users to', out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most talked-about topics overall and by country.\n",
    "topic_cols = [c for c in df.columns if any(k in c.lower() for k in ['topic','category','tag','theme'])]\n",
    "print('Topic-like columns detected:', topic_cols)\n",
    "country_cols = [c for c in df.columns if 'country' in c.lower()]\n",
    "country_col = country_cols[0] if country_cols else None\n",
    "if topic_cols:\n",
    "    t = topic_cols[0]\n",
    "    print('Top topics overall:')\n",
    "    display(df[t].value_counts().head(30))\n",
    "    if country_col is not None:\n",
    "        print(f'Top topics by country (sample for top 5 countries) grouping by {country_col}:')\n",
    "        top_countries = df[country_col].value_counts().head(5).index.tolist()\n",
    "        for ctry in top_countries:\n",
    "            print('---', ctry)\n",
    "            display(df[df[country_col] == ctry][t].value_counts().head(10))\n",
    "else:\n",
    "    print('No clear topic column detected. Consider running keyword extraction on `question` text to create topics.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse object date/time columns into datetime (UTC) and create *_dt columns.\n",
    "# This cell will populate dt_cols and set a preferred date_col for downstream cells.\n",
    "obj_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "date_keywords = ['sent', 'created_at', '_at', 'date', 'dt', 'time']\n",
    "cand_cols = [c for c in obj_cols if any(k in c.lower() for k in date_keywords)]\n",
    "\n",
    "dt_cols = []\n",
    "for col in cand_cols:\n",
    "    # try to parse with pandas (coerce errors). Keep timezone info if present, convert to UTC.\n",
    "    parsed = pd.to_datetime(df[col], utc=True, errors='coerce', infer_datetime_format=True)\n",
    "    parsed_count = int(parsed.notna().sum())\n",
    "    if parsed_count > 0:\n",
    "        new_col = f\"{col.rstrip('_').rstrip('.')}_dt\" if not col.endswith('_dt') else col\n",
    "        # avoid overwriting if exists but replace if present\n",
    "        df[new_col] = parsed\n",
    "        dt_cols.append(new_col)\n",
    "        print(f\"Parsed column '{col}' -> '{new_col}': {parsed_count}/{len(df)} non-null (sample values):\")\n",
    "        display(df[new_col].dropna().head(5))\n",
    "\n",
    "# Deduplicate dt_cols and prefer canonical names\n",
    "dt_cols = list(dict.fromkeys(dt_cols))\n",
    "print(\"Detected/created datetime columns:\", dt_cols)\n",
    "\n",
    "# Set a preferred date_col for activity plots and other analysis\n",
    "preferred_candidates = ['question_sent_dt','question_dt','response_sent_dt','response_dt']\n",
    "date_col = next((c for c in preferred_candidates if c in df.columns), dt_cols[0] if dt_cols else None)\n",
    "print(\"Using date column for downstream analysis:\", date_col)\n",
    "\n",
    "# Quick sanity checks for main columns expected by the notebook\n",
    "for expected in [question_ts_col, response_ts_col, 'question_user_created_at', 'response_user_created_at']:\n",
    "    if expected in df.columns:\n",
    "        parsed = pd.to_datetime(df[expected], utc=True, errors='coerce', infer_datetime_format=True)\n",
    "        non_null = int(parsed.notna().sum())\n",
    "        print(f\"Sanity parse: '{expected}' -> {non_null}/{len(df)} parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show up to 30 rows where the requested columns are all non-null\n",
    "required_cols = [\n",
    "    'response_sent',\n",
    "    'response_sent_dt',\n",
    "    'question_sent',\n",
    "    'question_sent_dt',\n",
    "    'response_user_created_at_dt',\n",
    "    'response_user_created_at',\n",
    "    'question_user_created_at_dt',\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency over time for question/response sent times and user-created times (monthly)\n",
    "cols_map = {\n",
    "    'question_sent_dt': 'Questions (sent)',\n",
    "    'question_user_created_at_dt': 'Askers (account created)',\n",
    "    'response_sent_dt': 'Responses (sent)',\n",
    "    'response_user_created_at_dt': 'Responders (account created)'\n",
    "}\n",
    "\n",
    "# Keep only columns that exist in the dataframe\n",
    "cols_present = {k: v for k, v in cols_map.items() if k in df.columns}\n",
    "if not cols_present:\n",
    "    print(\"No datetime columns found among:\", list(cols_map.keys()))\n",
    "else:\n",
    "    # Build monthly counts (Period M -> Timestamp for plotting)\n",
    "    counts = {}\n",
    "    for col, label in cols_present.items():\n",
    "        s = df[col].dropna()\n",
    "        # ensure datetime dtype\n",
    "        s = pd.to_datetime(s, utc=True, errors='coerce').dropna()\n",
    "        if len(s):\n",
    "            ser = s.dt.to_period('M').value_counts().sort_index()\n",
    "            ser.index = ser.index.to_timestamp()\n",
    "            counts[label] = ser\n",
    "        else:\n",
    "            counts[label] = pd.Series(dtype='int64')\n",
    "\n",
    "    # Combine into single DataFrame, fill missing months with 0\n",
    "    counts_df = pd.DataFrame(counts).fillna(0).astype(int)\n",
    "    counts_df = counts_df.sort_index()\n",
    "\n",
    "    # Quick summary: total counts and top months\n",
    "    print(\"Total counts (available columns):\")\n",
    "    print(counts_df.sum().to_frame('total_count'))\n",
    "    print(\"\\nTop 5 months per series:\")\n",
    "    for col in counts_df.columns:\n",
    "        top = counts_df[col].nlargest(5)\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(top)\n",
    "\n",
    "    # Plot monthly time series (all series on same plot)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    for col in counts_df.columns:\n",
    "        sns.lineplot(x=counts_df.index, y=counts_df[col], label=col)\n",
    "    plt.title('Monthly frequency: questions & responses (sent vs user_created)')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally show weekly aggregation for a denser trend (uncomment to use)\n",
    "    # counts_w = {}\n",
    "    # for col, label in cols_present.items():\n",
    "    #     s = pd.to_datetime(df[col], utc=True, errors='coerce').dropna()\n",
    "    #     counts_w[label] = s.dt.to_period('W').value_counts().sort_index()\n",
    "    # for k in counts_w:\n",
    "    #     counts_w[k].index = counts_w[k].index.to_timestamp()\n",
    "    # counts_w_df = pd.DataFrame(counts_w).fillna(0).astype(int).sort_index()\n",
    "    # display(counts_w_df.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
