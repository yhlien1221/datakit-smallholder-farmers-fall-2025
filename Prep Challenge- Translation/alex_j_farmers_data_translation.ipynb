{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNxjZFIhpddNtwRvXWp6iEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-jk/datakit-smallholder-farmers-fall-2025/blob/main/Prep%20Challenge-%20Translation/alex_j_farmers_data_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alex-J Farmer Survey Data: Translation Pipeline\n",
        "\n",
        "This notebook processes a dataset of survey questions and responses from smallholder farmers. The primary goal is to translate non-English text (specifically Swahili) into English to create a unified dataset for further analysis.\n",
        "\n",
        "### Workflow Overview:\n",
        "1.  **Setup & Data Loading:** The environment is configured by cloning the project repository and mounting Google Drive. The large survey CSV is loaded into a `duckdb` in-memory database and converted to the efficient Parquet format for faster querying.\n",
        "2.  **Exploratory Data Analysis (EDA):** Initial analysis is performed to understand the dataset's structure, size, language distribution, and overall data quality.\n",
        "3.  **Translation with a Hugging Face Model:** A free, open-source Swahili-to-English translation model from the Hugging Face Hub (`Bildad/Swahili-English_Translation`) is used to test the translation process on a small sample of the data.\n",
        "4.  **Sampling for Google Cloud Translation:** To manage costs for a higher-quality translation service, the notebook:\n",
        "    *   Estimates the potential cost of using the Google Cloud Translation API.\n",
        "    *   Implements a stratified sampling algorithm to create a representative 8,000-question sample, ensuring proportional representation from all question topics.\n",
        "    *   Exports this curated sample, preparing it for batch translation via the Google Cloud API."
      ],
      "metadata": {
        "id": "EIako103z34B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><font color=\"#0b3d91\">Clone the repo</font></h3>"
      ],
      "metadata": {
        "id": "mx_-lxS12iJq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "827DijlO2K2E"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "from google.colab import drive\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Always work from /content when checking / cloning the repo\n",
        "root_dir = \"/content\"\n",
        "repo_name = \"datakit-smallholder-farmers-fall-2025\"\n",
        "repo_dir = os.path.join(root_dir, repo_name)\n",
        "\n",
        "# Go to /content first\n",
        "%cd /content\n",
        "\n",
        "# Clone only if the repo directory does NOT exist in /content\n",
        "if not os.path.isdir(repo_dir):\n",
        "    !git clone https://github.com/alex-jk/datakit-smallholder-farmers-fall-2025.git\n",
        "\n",
        "# Now cd into the repo, then into the subfolder\n",
        "%cd {repo_dir}\n",
        "%cd \"Prep Challenge- Translation\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><font color=\"#0b3d91\">Load the farmers survey dataset</font></h3>"
      ],
      "metadata": {
        "id": "dBpbtUl76jat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "export_input_to_parquet = False\n",
        "run_sample_query = False\n",
        "perform_google_translate = False\n",
        "\n",
        "!pip install duckdb -q"
      ],
      "metadata": {
        "id": "JUjU2Xqp2jH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/DataKind Farmers Project/farmers_survey_dataset.csv\"\n",
        "parquet_path = \"/content/drive/MyDrive/DataKind Farmers Project/farmers_survey_dataset.parquet\"\n",
        "\n",
        "con = duckdb.connect()"
      ],
      "metadata": {
        "id": "CNfd3Ws3iP-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if export_input_to_parquet:\n",
        "\n",
        "  con.execute(f\"\"\"\n",
        "      COPY (\n",
        "          SELECT *\n",
        "          FROM read_csv_auto('{csv_path}', sample_size=-1)\n",
        "      )\n",
        "      TO '{parquet_path}'\n",
        "      (FORMAT PARQUET);\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "IpMfmWvRieKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connect to the DB**"
      ],
      "metadata": {
        "id": "1SSnFeFKlpsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parquet_path = \"/content/drive/MyDrive/DataKind Farmers Project/farmers_survey_dataset.parquet\"\n",
        "\n",
        "con.execute(f\"\"\"\n",
        "    CREATE OR REPLACE VIEW farmers AS\n",
        "    SELECT *\n",
        "    FROM read_parquet('{parquet_path}')\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "hU5zKhhui0FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Row count\n",
        "row_count_df = con.execute(\"SELECT COUNT(*) AS n_rows FROM farmers\").df()\n",
        "n_rows = int(row_count_df.loc[0, \"n_rows\"])\n",
        "\n",
        "# Column info\n",
        "cols_info = con.execute(\"PRAGMA table_info('farmers')\").df()\n",
        "n_cols = cols_info.shape[0]\n",
        "col_names = cols_info[\"name\"].tolist()\n",
        "\n",
        "print(f\"DF row count: {n_rows}\")\n",
        "print(f\"DF column count: {n_cols}\")\n",
        "print(\"Column names:\")\n",
        "print(col_names)\n",
        "\n",
        "# Peek at data\n",
        "con.execute(\"SELECT * FROM farmers LIMIT 5\").df()"
      ],
      "metadata": {
        "id": "rY3iAGN1ltBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check unique question counts**"
      ],
      "metadata": {
        "id": "YcjZRGw3oVpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Waiting 5 seconds before running query...\")\n",
        "time.sleep(5)\n",
        "\n",
        "questions_counts = con.execute(\"\"\"\n",
        "    SELECT\n",
        "        question_id,\n",
        "        question_topic,\n",
        "        question_content,\n",
        "        question_language,\n",
        "        COUNT(*) AS n_responses\n",
        "    FROM farmers\n",
        "    GROUP BY\n",
        "        question_id,\n",
        "        question_topic,\n",
        "        question_content,\n",
        "        question_language\n",
        "    ORDER BY\n",
        "        n_responses DESC\n",
        "\"\"\").df()\n",
        "\n",
        "print(questions_counts.shape)\n",
        "# display(questions_counts)"
      ],
      "metadata": {
        "id": "q-ZxlhbkoY2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check if each question ID corresponds to a unique question**"
      ],
      "metadata": {
        "id": "CvPtjdKWsnWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All question_ids where there is more than 1 distinct question_content\n",
        "qid_conflicts = con.execute(\"\"\"\n",
        "    SELECT\n",
        "        question_id,\n",
        "        COUNT(DISTINCT question_content) AS n_question_contents\n",
        "    FROM farmers\n",
        "    GROUP BY question_id\n",
        "    HAVING COUNT(DISTINCT question_content) > 1\n",
        "    ORDER BY n_question_contents DESC\n",
        "\"\"\").df()\n",
        "\n",
        "qid_conflicts"
      ],
      "metadata": {
        "id": "flYH_8Spr_D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check questions and responses**"
      ],
      "metadata": {
        "id": "VRZ06hUPuEuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "\n",
        "qid_counts_by_lang = con.execute(\"\"\"\n",
        "    SELECT\n",
        "        question_language,\n",
        "        COUNT(DISTINCT question_id) AS n_unique_question_ids\n",
        "    FROM farmers\n",
        "    GROUP BY question_language\n",
        "    ORDER BY question_language\n",
        "\"\"\").df()\n",
        "\n",
        "qid_counts_by_lang[\"n_unique_question_ids_fmt\"] = (\n",
        "    qid_counts_by_lang[\"n_unique_question_ids\"].astype(int).map(\"{:,}\".format)\n",
        ")\n",
        "\n",
        "display(qid_counts_by_lang)\n",
        "\n",
        "select_lang = \"swa\"  # or \"swa\", \"lug\", ...\n",
        "\n",
        "sample_lang = con.execute(\"\"\"\n",
        "    SELECT\n",
        "        question_id,\n",
        "        question_topic,\n",
        "        question_content,\n",
        "        response_content,\n",
        "        question_language\n",
        "    FROM farmers\n",
        "    WHERE question_language = ?\n",
        "      AND question_content IS NOT NULL\n",
        "      AND response_content IS NOT NULL\n",
        "    ORDER BY random()\n",
        "    LIMIT 20\n",
        "\"\"\", [select_lang]).df()\n",
        "\n",
        "print(f\"\\n-------Questions Sample {select_lang}------\\n\")\n",
        "display(sample_lang)"
      ],
      "metadata": {
        "id": "jdipdvNyuGf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><font color=\"#0b3d91\">Translation</font></h3>"
      ],
      "metadata": {
        "id": "OKldRQym0L7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub -q\n",
        "\n",
        "from huggingface_hub import HfFolder\n",
        "\n",
        "# Remove any stored token so transformers uses anonymous access\n",
        "HfFolder.delete_token()"
      ],
      "metadata": {
        "id": "DeqKxy933TBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece accelerate -q\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"Bildad/Swahili-English_Translation\"  # Swahili <-> English\n",
        "\n",
        "print(\"Loading tokenizer and model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded.\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --- quick sanity check for inference ---\n",
        "try:\n",
        "    test_texts = [\"Dawa ya minyoo ya kuku ni gani?\"]\n",
        "    enc = tokenizer(\n",
        "        test_texts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=64,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**enc, max_length=64, num_beams=1)\n",
        "\n",
        "    test_translation = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
        "    print(\"Sanity check translation OK:\")\n",
        "    print(\"  Input :\", test_texts[0])\n",
        "    print(\"  Output:\", test_translation[0])\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Sanity check FAILED, model not ready for inference.\")\n",
        "    print(\"Error:\", repr(e))"
      ],
      "metadata": {
        "id": "Gnss-dst1qWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_batch(texts, max_length=128):\n",
        "    \"\"\"Translate a list of Swahili strings to English.\"\"\"\n",
        "    texts = [t if isinstance(t, str) else \"\" for t in texts]\n",
        "\n",
        "    enc = tokenizer(\n",
        "        texts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**enc, max_length=max_length)\n",
        "\n",
        "    return tokenizer.batch_decode(out, skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "qV_YaOx34BRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test translator on a sample if questions**"
      ],
      "metadata": {
        "id": "Mro7vTV14lJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate the question_content column with a progress bar\n",
        "texts = sample_lang[\"question_content\"].tolist()\n",
        "\n",
        "batch_size = 32  # or 64/128 depending on how heavy the model is\n",
        "all_translations = []\n",
        "\n",
        "for i in tqdm(range(0, len(texts), batch_size)):\n",
        "    batch = texts[i:i + batch_size]\n",
        "    batch_translations = translate_batch(batch)\n",
        "    all_translations.extend(batch_translations)\n",
        "\n",
        "# Attach translations back to the DataFrame\n",
        "sample_lang[\"question_content_en\"] = all_translations\n",
        "\n",
        "# Display original + translation\n",
        "sample_lang[[\n",
        "    \"question_id\",\n",
        "    \"question_topic\",\n",
        "    \"question_content\",\n",
        "    \"question_content_en\",\n",
        "]]"
      ],
      "metadata": {
        "id": "OdeDpAsp4nro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><font color=\"#0b3d91\"><b>Calculate Google API translation</b></font></h4>"
      ],
      "metadata": {
        "id": "4BJgJilnV9-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Helper: estimate cost given a list/Series of texts ---\n",
        "def estimate_translate_cost(texts, free_chars=500_000, price_per_million=20.0):\n",
        "    \"\"\"\n",
        "    texts: iterable of strings (each element = what you'd send as *one* request to Google)\n",
        "    free_chars: monthly free tier characters (Google Cloud Translation)\n",
        "    price_per_million: USD per 1,000,000 billable characters\n",
        "    \"\"\"\n",
        "    # Ensure strings, ignore None/NaN\n",
        "    lengths = [len(t) for t in texts if isinstance(t, str)]\n",
        "    total_chars = sum(lengths)\n",
        "\n",
        "    free_used = min(total_chars, free_chars)\n",
        "    billable_chars = max(0, total_chars - free_chars)\n",
        "    cost_usd = billable_chars / 1_000_000 * price_per_million\n",
        "\n",
        "    avg_chars_per_row = (total_chars / len(lengths)) if lengths else 0\n",
        "    rows_free = int(free_chars // avg_chars_per_row) if avg_chars_per_row > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"n_rows\": len(lengths),\n",
        "        \"total_chars\": total_chars,\n",
        "        \"avg_chars_per_row\": avg_chars_per_row,\n",
        "        \"free_chars_available\": free_chars,\n",
        "        \"free_chars_used\": free_used,\n",
        "        \"billable_chars\": billable_chars,\n",
        "        \"estimated_cost_usd\": cost_usd,\n",
        "        \"approx_rows_free_at_this_avg\": rows_free,\n",
        "    }\n",
        "\n",
        "# --- 2. Pull 7K rows from your actual farmers data ---\n",
        "select_lang = \"swa\"  # or \"swa\", \"lug\", ...\n",
        "\n",
        "df_7k = con.execute(\"\"\"\n",
        "    SELECT\n",
        "        question_id,\n",
        "        question_content,\n",
        "        response_content,\n",
        "        question_language\n",
        "    FROM farmers\n",
        "    WHERE question_language = ?\n",
        "       AND question_content IS NOT NULL\n",
        "       AND response_content IS NOT NULL\n",
        "    ORDER BY question_id\n",
        "    LIMIT 7000\n",
        "\"\"\", [select_lang]).df()\n",
        "\n",
        "print(\"Sample shape:\", df_7k.shape)\n",
        "\n",
        "# Combine question + response into what you'd actually send to Google as one string\n",
        "combined_7k = (\n",
        "    df_7k[\"question_content\"].fillna(\"\")\n",
        "    + \"\\n\"\n",
        "    + df_7k[\"response_content\"].fillna(\"\")\n",
        ")\n",
        "\n",
        "# --- 3. Estimate cost for THESE EXACT 7K ROWS ---\n",
        "result_7k = estimate_translate_cost(combined_7k)\n",
        "\n",
        "print(\"Rows:\", result_7k[\"n_rows\"])\n",
        "print(\"Total characters:\", result_7k[\"total_chars\"])\n",
        "print(\"Average chars per row:\", round(result_7k[\"avg_chars_per_row\"], 1))\n",
        "print(\"Free chars available:\", result_7k[\"free_chars_available\"])\n",
        "print(\"Free chars used in this 7K:\", result_7k[\"free_chars_used\"])\n",
        "print(\"Billable chars (beyond free):\", result_7k[\"billable_chars\"])\n",
        "print(\"Estimated cost for these 7K (USD):\", round(result_7k[\"estimated_cost_usd\"], 2))\n",
        "print(\"At this average length, approx rows you could translate for free:\",\n",
        "      result_7k[\"approx_rows_free_at_this_avg\"])\n",
        "\n",
        "combined_7k = (\n",
        "    df_7k[\"question_content\"].fillna(\"\")\n",
        "    + \"\\n\"\n",
        "    + df_7k[\"response_content\"].fillna(\"\")\n",
        ")\n",
        "\n",
        "total_chars = combined_7k.str.len().sum()\n",
        "avg_chars = combined_7k.str.len().mean()\n",
        "\n",
        "print(\"Total chars:\", total_chars)\n",
        "print(\"Avg chars/row:\", avg_chars)"
      ],
      "metadata": {
        "id": "71M6PXPBWCVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><font color=\"#0b3d91\"><b>Questions selection for Google translation</b></font></h4>\n",
        "This code creates a view of unique <b>Q&A pairs per question</b> (for a chosen language), picks one primary topic per question, and counts how many questions fall under each topic.<br>It then designs a sampling plan for exactly <b>N</b> questions: every topic gets at least one row and the remaining rows are allocated proportionally to topic frequency, with a final adjustment so the total sample size is exactly <b>N</b> and all topics are represented."
      ],
      "metadata": {
        "id": "L62s0feJgByI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_total = 8000\n",
        "\n",
        "con.execute(f\"\"\"\n",
        "    CREATE OR REPLACE VIEW swa_unique_questions AS\n",
        "    SELECT\n",
        "        question_id,\n",
        "        -- choose ONE primary topic per question for sampling\n",
        "        MIN(question_topic) AS primary_topic,\n",
        "        -- all topics for information\n",
        "        STRING_AGG(DISTINCT question_topic, ',') AS all_topics,\n",
        "        -- representative texts\n",
        "        MAX(question_content)  AS question_content,\n",
        "        MAX(response_content)  AS response_content,\n",
        "        question_language\n",
        "    FROM farmers\n",
        "    WHERE question_language = '{select_lang}'\n",
        "      AND question_content IS NOT NULL\n",
        "      AND response_content IS NOT NULL\n",
        "    GROUP BY\n",
        "        question_id,\n",
        "        question_language\n",
        "\"\"\")\n",
        "\n",
        "topic_counts = con.execute(\"\"\"\n",
        "    SELECT\n",
        "        primary_topic AS question_topic,\n",
        "        COUNT(*) AS n_rows\n",
        "    FROM swa_unique_questions\n",
        "    GROUP BY primary_topic\n",
        "\"\"\").df()\n",
        "\n",
        "n_topics_total = topic_counts.shape[0]\n",
        "\n",
        "topic_counts[\"base\"] = 1\n",
        "remaining = target_total - n_topics_total\n",
        "if remaining <= 0:\n",
        "    raise ValueError(\"target_total too small to give every topic at least 1 row\")\n",
        "\n",
        "weights = topic_counts[\"n_rows\"] / topic_counts[\"n_rows\"].sum()\n",
        "topic_counts[\"extra\"] = (weights * remaining).round().astype(int)\n",
        "topic_counts[\"sample_n\"] = topic_counts[\"base\"] + topic_counts[\"extra\"]\n",
        "\n",
        "diff = target_total - topic_counts[\"sample_n\"].sum()\n",
        "if diff > 0:\n",
        "    idx = topic_counts[\"n_rows\"].sort_values(ascending=False).index[:diff]\n",
        "    topic_counts.loc[idx, \"sample_n\"] += 1\n",
        "elif diff < 0:\n",
        "    candidates = topic_counts[topic_counts[\"sample_n\"] > 1].sort_values(\n",
        "        \"sample_n\", ascending=False\n",
        "    ).index[: -diff]\n",
        "    topic_counts.loc[candidates, \"sample_n\"] -= 1\n",
        "\n",
        "print(\"Final planned total:\", topic_counts[\"sample_n\"].sum())\n",
        "print(\"Total topics in data:\", n_topics_total)\n",
        "print(\"Topics represented in sample:\", (topic_counts[\"sample_n\"] > 0).sum())"
      ],
      "metadata": {
        "id": "NwJlvDkSgFo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><font color=\"#0b3d91\"><b>Select final questions for the sample</b></font></h4>\n",
        "This cell builds a view <b>`swa_unique_questions`</b> of unique questions per <b>`question_id`</b> and language, choosing one primary topic per question, aggregating all topics, and keeping representative question/response text. It then counts how many questions fall under each primary topic and designs a sampling plan for a fixed total of <b>N</b> questions. <br>Every topic is guaranteed at least one question, and the remaining sample slots are distributed proportionally to topic frequency, with a final adjustment step to ensure the total sample size is exactly <b>N</b>. <br>It prints the planned total sample size, the number of topics in the data, and how many topics are represented in the sample.\n"
      ],
      "metadata": {
        "id": "AeNccTbplvtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_samples = []\n",
        "\n",
        "if run_sample_query:\n",
        "    for _, row in topic_counts.iterrows():\n",
        "        topic = row[\"question_topic\"]      # this is primary_topic from topic_counts\n",
        "        k = int(row[\"sample_n\"])\n",
        "        if k <= 0:\n",
        "            continue\n",
        "\n",
        "        if pd.isna(topic):  # topic is NULL / None\n",
        "            df_topic = con.execute(\"\"\"\n",
        "                SELECT\n",
        "                    question_id,\n",
        "                    primary_topic AS question_topic,\n",
        "                    all_topics,\n",
        "                    question_content,\n",
        "                    response_content,\n",
        "                    question_language\n",
        "                FROM swa_unique_questions\n",
        "                WHERE primary_topic IS NULL\n",
        "                ORDER BY hash(question_id)         -- deterministic\n",
        "                LIMIT ?\n",
        "            \"\"\", [k]).df()\n",
        "        else:  # normal non-null topic\n",
        "            df_topic = con.execute(\"\"\"\n",
        "                SELECT\n",
        "                    question_id,\n",
        "                    primary_topic AS question_topic,\n",
        "                    all_topics,\n",
        "                    question_content,\n",
        "                    response_content,\n",
        "                    question_language\n",
        "                FROM swa_unique_questions\n",
        "                WHERE primary_topic = ?\n",
        "                ORDER BY hash(question_id)\n",
        "                LIMIT ?\n",
        "            \"\"\", [topic, k]).df()\n",
        "\n",
        "        all_samples.append(df_topic)\n",
        "\n",
        "    df_sample = pd.concat(all_samples, ignore_index=True)\n",
        "    print(\"Initial sample size (rows):\", df_sample.shape[0])\n",
        "    print(\"Unique question_ids:\", df_sample[\"question_id\"].nunique())\n",
        "\n",
        "    # If slightly above target_total, trim once with fixed seed\n",
        "    if df_sample.shape[0] > target_total:\n",
        "        df_sample = df_sample.sample(n=target_total, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    print(\"Final sample size (rows):\", df_sample.shape[0])\n",
        "    print(\"Final unique question_ids:\", df_sample[\"question_id\"].nunique())"
      ],
      "metadata": {
        "id": "isSBi9FXlx7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if run_sample_query:\n",
        "  sample_path = \"/content/drive/MyDrive/DataKind Farmers Project/farmers_swa_sample.parquet\"\n",
        "\n",
        "  df_sample = df_sample.drop_duplicates().reset_index(drop=True)\n",
        "  print(f\"\\nDF SAMPLE num rows: {len(df_sample.index)}\")\n",
        "\n",
        "  df_sample.to_parquet(sample_path, index=False)\n",
        "  print(\"Saved sample to:\", sample_path)"
      ],
      "metadata": {
        "id": "bFMJDZv3E0-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4><font color=\"#0b3d91\"><b>Translate sample questions</b></font></h4>\n",
        "<b>Import DF sample</b>"
      ],
      "metadata": {
        "id": "VmWw-FHdHv34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_path = \"/content/drive/MyDrive/DataKind Farmers Project/farmers_swa_sample.parquet\"\n",
        "\n",
        "df_sample = pd.read_parquet(sample_path)\n",
        "print(df_sample.shape)\n",
        "\n",
        "n_topics_sample = df_sample[\"question_topic\"].nunique()\n",
        "print(\"Unique topics in sample:\", n_topics_sample)\n",
        "print(f\"\\nNumber of unique question IDs in the sample: {len(df_sample['question_id'].unique())}\")\n",
        "print(f\"\\nNumber of question content in the sample: {len(df_sample['question_content'].unique())}\")\n",
        "\n",
        "df_sample.head()"
      ],
      "metadata": {
        "id": "nxKn97yNHyHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-cloud-translate\n",
        "\n",
        "from google.cloud import translate_v2 as translate"
      ],
      "metadata": {
        "id": "1oYpfGx1RscW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "mjil6jCtmTw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creds_path = os.path.join(os.getcwd(), \"farmers-survey-translation-key.json\")\n",
        "print(\"Using credentials file:\", creds_path)\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = creds_path\n",
        "\n",
        "translate_client = translate.Client()\n",
        "\n",
        "# sanity check\n",
        "test = translate_client.translate(\n",
        "    \"Dawa ya minyoo ya kuku ni gani?\",\n",
        "    source_language=\"sw\",\n",
        "    target_language=\"en\",\n",
        "    format_=\"text\",\n",
        ")\n",
        "print(\"Test translation:\", test[\"translatedText\"])"
      ],
      "metadata": {
        "id": "sDdIqjFImmmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_list(texts, source=\"sw\", target=\"en\", batch_size=128):\n",
        "    \"\"\"\n",
        "    Translate a list/Series of strings with Google Cloud Translation.\n",
        "    Returns a list of translated strings in the same order.\n",
        "    \"\"\"\n",
        "    texts = list(texts)\n",
        "    out = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Translating\"):\n",
        "        batch = [t if isinstance(t, str) else \"\" for t in texts[i:i+batch_size]]\n",
        "        if not batch:\n",
        "            continue\n",
        "\n",
        "        result = translate_client.translate(\n",
        "            batch,\n",
        "            source_language=source,\n",
        "            target_language=target,\n",
        "            format_=\"text\",\n",
        "        )\n",
        "        out.extend([r[\"translatedText\"] for r in result])\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "CTW5bUwSntT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if perform_google_translate:\n",
        "  # Translate question_content\n",
        "  q_texts = df_sample[\"question_content\"]\n",
        "  q_en = translate_list(q_texts, source=\"sw\", target=\"en\", batch_size=128)\n",
        "  df_sample[\"question_content_google_en\"] = q_en\n",
        "\n",
        "  # Quick check\n",
        "  df_sample[[\n",
        "      \"question_id\",\n",
        "      \"question_content\",\n",
        "      \"question_content_google_en\"\n",
        "  ]].head(25)\n",
        "\n",
        "  len_q_texts = len(df_sample[\"question_content\"])\n",
        "  len_q_en = len(q_en)\n",
        "\n",
        "  print(\"Rows in df_sample:\", len_q_texts)\n",
        "  print(\"Translations returned:\", len_q_en)\n",
        "\n",
        "  print(\"Missing translations in column:\",\n",
        "        df_sample[\"question_content_google_en\"].isna().sum())"
      ],
      "metadata": {
        "id": "rpQDWl1AolUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if perform_google_translate:\n",
        "  out_parquet = \"/content/drive/MyDrive/DataKind Farmers Project/swa_unique_q_8k_google_translated.parquet\"\n",
        "\n",
        "  # save Parquet\n",
        "  df_sample.to_parquet(out_parquet, index=False)\n",
        "  print(\"Saved Parquet to:\", out_parquet)"
      ],
      "metadata": {
        "id": "7B2i3ZMUpmYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}